import argparse
import os
import shutil
import cv2
import numpy as np
import csv

def parse_args():
    parser = argparse.ArgumentParser(description="Extract frames from video, apply sharpening, binarization, compute similarity with reference image, and generate subtitles.")
    parser.add_argument("--input", type=str, required=True, help="Path to the input video file.")
    parser.add_argument("--output", type=str, default="tmp-frame", help="Output directory for similarity results.")
    parser.add_argument("--debug", action="store_true", help="Enable debug mode to save tmp_frame images.")
    parser.add_argument("--slides", action="store_true", help="Enable slides generation for high similarity intervals.")
    return parser.parse_args()

def is_valid_aspect_ratio(width, height):
    return abs((width / height) - (9 / 16)) < 0.05

def enhance_sharpness(image):
    kernel = np.array([[-1, -1, -1],
                       [-1, 9, -1],
                       [-1, -1, -1]])
    return cv2.filter2D(image, -1, kernel)

def binarize_image(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return binary

def compute_similarity(image1, image2):
    image2_resized = cv2.resize(image2, (image1.shape[1], image1.shape[0]))
    diff = cv2.absdiff(image1, image2_resized)
    similarity = 1 - (np.sum(diff) / (255 * image1.shape[0] * image1.shape[1]))
    return similarity

def extract_frames(video_path, output_dir, debug, slides):
    if debug:
        if os.path.exists(output_dir):
            shutil.rmtree(output_dir)
        os.makedirs(output_dir, exist_ok=True)
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("Error: Cannot open video file.")
        return
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    if not is_valid_aspect_ratio(frame_width, frame_height):
        print("Error: Video does not have a 9:16 aspect ratio.")
        cap.release()
        return
    
    reference_path = os.path.join(os.path.dirname(__file__), "kuroyuri.png")
    if not os.path.exists(reference_path):
        print("Error: Reference image 'kuroyuri.png' not found in script directory.")
        cap.release()
        return
    
    reference_image = cv2.imread(reference_path, cv2.IMREAD_GRAYSCALE)
    
    scale_x = frame_width / 1080
    scale_y = frame_height / 1920
    
    x1, y1 = int(942 * scale_x), int(1554 * scale_y)
    x2, y2 = int(1015 * scale_x), int(1634 * scale_y)
    
    frame_count = 0
    similarities = []
    high_similarity_intervals = []
    active_interval = None
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        time_stamp = frame_count / fps
        cropped_frame = frame[y1:y2, x1:x2]
        sharpened_frame = enhance_sharpness(cropped_frame)
        binary_frame = binarize_image(sharpened_frame)
        
        if debug:
            frame_filename = os.path.join(output_dir, f"{frame_count:06d}.png")
            cv2.imwrite(frame_filename, binary_frame)
        
        similarity = compute_similarity(binary_frame, reference_image)
        similarities.append([frame_count, similarity])
        
        if similarity > 0.86:
            if active_interval is None:
                active_interval = [None, None]  # 开始时间稍后填充
            active_interval[1] = time_stamp  # 结束时间更新
        
        if active_interval is not None and similarity < 0.9:
            if not high_similarity_intervals or (time_stamp - high_similarity_intervals[-1][1] > 1.0):
                if high_similarity_intervals:
                    active_interval[0] = high_similarity_intervals[-1][1] + 0.1  # 上一个字幕的结束时间 + 0.1s
                else:
                    active_interval[0] = 0.0  # 第一段字幕从0开始
                high_similarity_intervals.append(active_interval)
            else:
                high_similarity_intervals[-1][1] = time_stamp  # 合并相邻的毛刺段
            active_interval = None
        
        frame_count += 1
    
    cap.release()
    
    if debug:
        csv_path = os.path.join(output_dir, "_a.csv")
        with open(csv_path, mode="w", newline="") as csv_file:
            writer = csv.writer(csv_file)
            writer.writerow(["Frame", "Similarity"])
            writer.writerows(similarities)

    video_dir, video_filename = os.path.split(video_path)
    video_name, _ = os.path.splitext(video_filename)
    subtitle_path = os.path.join(video_dir, f"{video_name}.ass")
    
    with open(subtitle_path, "w") as sub_file:
        sub_file.write("[Script Info]\n")
        sub_file.write("Title: AutoGenerated\n")
        sub_file.write("ScriptType: v4.00+\n")
        sub_file.write("PlayResX: 720\n")
        sub_file.write("PlayResY: 1280\n\n")
        sub_file.write("[V4+ Styles]\n")
        sub_file.write("Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n")
        sub_file.write("Style: Default,Arial,40,&H00FFFFFF,&H00000000,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,3,1,2,10,10,10,1\n\n")
        sub_file.write("[Events]\n")
        sub_file.write("Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n")
        
        seq = 1
        for start_time, end_time in high_similarity_intervals:
            start_str = f"0:{int(start_time / 60):02}:{start_time % 60:.2f}".replace('.',',')
            end_str = f"0:{int(end_time / 60):02}:{end_time % 60:.2f}".replace('.',',')
            sub_file.write(f"Dialogue: 0,{start_str},{end_str},Default,,0,0,0,,{seq}\n")
            seq += 1
    
    if slides:
        slides_dir = os.path.join(video_dir, "slides")
        if os.path.exists(slides_dir):
            shutil.rmtree(slides_dir)
        os.makedirs(slides_dir, exist_ok=True)

        for seq, (start_time, end_time) in enumerate(high_similarity_intervals, start=1):
            frame_target = int(end_time * fps) - 2
            cap = cv2.VideoCapture(video_path)
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_target)
            ret, frame = cap.read()
            if ret:
                x1_s, y1_s = int(80 * scale_x), int(1290 * scale_y)
                x2_s, y2_s = int(945 * scale_x), int(1610 * scale_y)
                slide_frame = frame[y1_s:y2_s, x1_s:x2_s]
                slide_path = os.path.join(slides_dir, f"{seq:06d}.png")
                cv2.imwrite(slide_path, slide_frame)
            cap.release()
    
    print(f"Extracted {frame_count} frames, and generated subtitles at {subtitle_path}")
    if debug:
        print(f"Saved frame images and similarity data at {output_dir}")

if __name__ == "__main__":
    args = parse_args()
    extract_frames(args.input, args.output, args.debug, args.slides)
